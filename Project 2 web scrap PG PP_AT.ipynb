{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping PG PP with Beautful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from __future__ import print_function, division\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import dateutil.parser\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import time, os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chromedriver = 'C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chromedriver.exe' # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page1(link1):\n",
    "    \n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    \n",
    "    driver.get(link1)\n",
    "    \n",
    "    page_info1 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "  \n",
    "    \n",
    "    return(page_info1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data):\n",
    "    #Get Address information\n",
    "    \n",
    "    adds = []\n",
    "    for add in data.find_all(itemprop=\"streetAddress\"):\n",
    "        adds.append(add.text)\n",
    "       \n",
    "              \n",
    "    #Get bedroom information\n",
    "    bedrms = []\n",
    "    for bedrm in data.find_all('span', class_=\"bed\"):\n",
    "        bedrms.append(int(bedrm.text))\n",
    "        \n",
    "     #Get bathroom information\n",
    "    baths = []\n",
    "    for bath in data.find_all('span', class_=\"bath\"):\n",
    "        baths.append(int(bath.text))\n",
    "    \n",
    "    #Get sqft and psf information \n",
    "    f_area = []\n",
    "    psf = []    \n",
    "    for flr in data.find_all('li',class_=\"listing-floorarea pull-left\"):\n",
    "        raw_f_area=flr.text\n",
    "        if raw_f_area.find(\"sqft\") > 0:\n",
    "            raw_f_area = raw_f_area.split(\" \")\n",
    "            raw_f_area = raw_f_area[0]\n",
    "            f_area.append(int(raw_f_area))\n",
    "        else:\n",
    "            raw_f_area = str(raw_f_area.strip(\"\\xa0psf\"))\n",
    "            raw_psf = raw_f_area[3:11]\n",
    "            psf.append(raw_psf)\n",
    "    \n",
    "    # #Get price information \n",
    "    prices = []\n",
    "    for price in data.find_all('span', class_=\"price\"):\n",
    "        prices.append(price.text)\n",
    "       \n",
    "    # soup.find_all('a', class_='nav-link')\n",
    "    links = []\n",
    "    for link in data.find_all(class_='nav-link'):\n",
    "        links.append(link.get(\"href\"))\n",
    "    \n",
    "    print(adds)\n",
    "    print(bedrms)\n",
    "    print(baths)\n",
    "    print(f_area,)\n",
    "    print(psf)\n",
    "    print(prices)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # setting up dataframe \n",
    "    headers =['Address', 'Bedrooms','Baths', 'Floor Area', 'PSF','Price','Link']\n",
    "    #Create  dictionary and return\n",
    "    PP_dict = dict(zip(headers, [adds, bedrms,baths,f_area,psf,prices,links])) \n",
    "    main_list = pd.DataFrame(PP_dict)\n",
    "    print(mainlist)\n",
    "    main_list.to_csv('main_list.csv')           \n",
    "            \n",
    "            \n",
    "            \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_to_int(moneystring):\n",
    "    if moneystring.find(',') > 0 :\n",
    "        moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    else:\n",
    "        moneystring = \"NaN\"\n",
    "    return (moneystring)\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    \n",
    "    # Request for html page 1 and 2 \n",
    "    url_1 = 'https://www.propertyguru.com.sg/property-for-sale?market=residential'\n",
    "    url_2 = 'https://www.propertyguru.com.sg/property-for-sale/' # PAge 2 to 3606  \n",
    "    \n",
    "    page1 = get_page1(url_1)#get page 1 info\n",
    "    \n",
    "    get_info(page1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['264B Compassvale Bow', 'Figaro Street', '1M Pine Grove', '2 Fourth Avenue', '2 Fourth Avenue', '6 Ridgewood Close', 'Hillview Rise', '60 Havelock Road', 'Jalan Loyang Besar', '205 Jalan Loyang Besar', 'Yuk Tong Avenue', '2 Anamalai Avenue', '85 Pheng Geck Avenue', '59 Ang Mo Kio Avenue 8', '7 Rivervale Link', '1 Shenton Way', '72 Dakota Crescent', '669D Jurong West Street 64', '511 Bukit Batok Street 52', '665A Punggol Drive']\n",
      "[3, 5, 4, 3, 2, 4, 2, 4, 3, 3, 6, 2, 3, 3, 3, 3, 2, 3, 3, 3]\n",
      "[2, 7, 3, 3, 2, 4, 2, 4, 3, 3, 6, 1, 3, 2, 3, 3, 1, 2, 2, 2]\n",
      "[990, 4551, 1927, 947, 646, 2153, 775, 2110, 1206, 1206, 4000, 635, 1281, 1001, 1314, 1593, 624, 1399, 1313, 1001]\n",
      "['419.19', '2,589.29', '960.04', '2,171.07', '2,102.17', '1,802.14', '1,483.87', '1,507.11', '995.02', '995.02', '999.36', '2,527.56', '1,327.09', '1,478.52', '722.98', '1,881.98', '1,858.97', '393.14', '367.10', '519.48']\n",
      "['415,000', '3,770,000', '1,850,000', '2,056,000', '1,358,000', '3,880,000', '1,150,000', '3,180,000', '1,200,000', '1,200,000', '6,290,000', '1,605,000', '1,700,000', '1,480,000', '950,000', '2,998,000', '1,160,000', '550,000', '482,000', '520,000']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-167a19ccadd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#page2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b7a6942167b3>\u001b[0m in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpage1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_page1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#get page 1 info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mget_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-56e6996572ca>\u001b[0m in \u001b[0;36mget_info\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m#Create  dictionary and return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mPP_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0madds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbedrms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbaths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_area\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpsf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mmain_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPP_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mmain_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main_list.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\metis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#activiation page\n",
    "\n",
    "\n",
    "start()\n",
    "\n",
    "#page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set up for page 2 until last page\n",
    "    counter = 2\n",
    "    total pages = 10\n",
    "    \n",
    "    for total pagers\n",
    "        url = url_2 + str(counter)\n",
    "         \n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(url)\n",
    "        page_info2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        get_info(page_info2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_1 = {}\n",
    "# movies_2 = {}\n",
    "\n",
    "#for row in rows_1[]:\n",
    "items = page.find_all('nav-link')\n",
    "\n",
    "for div in page.find_all('a class', class_='nav-link lazy-bg-parent'):\n",
    "    for link in div.find_all('href'):\n",
    "        print(link)\n",
    "\n",
    "#for item in rows_1[]:\n",
    " #   link = items[].find('a')\n",
    "  #  title, url = link.text, link['href']\n",
    "   # movies_1[title] = [url] + [i.text for i in items]\n",
    "    \n",
    "    \n",
    "#for row in rows_2[1:163]:\n",
    " #   items = row.find_all('td')\n",
    "  #  link = items[0].find('a')\n",
    "   # title, url = link.text, link['href']\n",
    "    #movies_2[title] = [url] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents_div = soup.find('div class', id='')\n",
    "\n",
    "# print(contents_div)\n",
    "\n",
    "# for title in contents_div.find_all('span class', id='price'):\n",
    "    #print(title.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_1 = BeautifulSoup(page_1,\"html5lib\")\n",
    "#soup_2 = BeautifulSoup(page_2,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_1 = soup_1.find('table')\n",
    "#table_2 = soup_2.find('table')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_1 = [row for row in table_1.find_all('tr')]  # tr tag is for rows\n",
    "rows_2 = [row for row in table_2.find_all('tr')]  # tr tag is for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_1.update(movies_2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_1 = pd.DataFrame(movies_1).T  #transpose\n",
    "g_movies_1.columns = ['link_stub','movie_title','rank_g_movies',   \n",
    "                    'lifetime_gross', 'rank_overall', 'year']\n",
    "\n",
    "g_movies_2 = pd.DataFrame(movies_2).T  #transpose\n",
    "g_movies_2.columns = ['link_stub','movie_title','rank_g_movies',   \n",
    "                    'lifetime_gross', 'rank_overall', 'year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_df =  df_row = pd.concat([g_movies_1, g_movies_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_movies_df.set_index('movie_title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_to_int(moneystring):\n",
    "    if moneystring.find(',') > 0 :\n",
    "        moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    else:\n",
    "        moneystring = \"NaN\"\n",
    "    return (moneystring)\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_dict(link):\n",
    "    '''\n",
    "    From BoxOfficeMojo link stub, request movie html, parse with BeautifulSoup, and\n",
    "    collect \n",
    "        - title \n",
    "        - domestic gross\n",
    "        - runtime \n",
    "        - MPAA rating\n",
    "        - full release date\n",
    "        - genre\n",
    "    Return information as a dictionary.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://www.boxofficemojo.com'\n",
    "    \n",
    "    #Create full url to scrape\n",
    "    url = base_url + link\n",
    "    \n",
    "    #Request HTML and parse\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    headers = ['link_stub','domestic_distributor','budget', 'domestic_total_gross',\n",
    "               'runtime_minutes', 'rating', 'release_date', 'Genres'] # removed 'movie_title',\n",
    "    \n",
    "    #use  link_sub as index\n",
    "    link_stub = link\n",
    "    \n",
    "    #Get domestic_distributor\n",
    "    raw_dd = str(get_movie_value(soup, 'Domestic Distributor') )\n",
    "    \n",
    "    if raw_dd.find('See full company information') > 0 :\n",
    "        raw_dd = raw_dd.replace(\"See full company information\", \"\")\n",
    "        dd = str(raw_dd.strip('\\n'))\n",
    "    else:  \n",
    "        raw_dd = raw_dd.strip()\n",
    "        dd = str(raw_dd.strip('\\n'))\n",
    "    \n",
    "    \n",
    "    raw_budget = str(get_movie_value(soup, 'Budget'))\n",
    "    #raw_budget = str(get_movie_value(soup, 'budget') )\n",
    "    \n",
    "    raw_budget = raw_budget.strip()\n",
    "    budget_value = money_to_int(raw_budget)\n",
    "    \n",
    "      \n",
    "    \n",
    "    #Get title\n",
    "    # title_string = soup.find('title').text\n",
    "    # title = title_string.split('-')[0].strip()\n",
    "\n",
    "    #Get domestic gross\n",
    "    raw_domestic_total_gross = (soup.find(class_='mojo-performance-summary-table')\n",
    "                                    .find_all('span', class_='money')[0]\n",
    "                                    .text\n",
    "                               )\n",
    "    domestic_total_gross = money_to_int(raw_domestic_total_gross)\n",
    "\n",
    "    #Get runtime\n",
    "    raw_runtime = get_movie_value(soup,'Running')\n",
    "    runtime = runtime_to_minutes(raw_runtime)\n",
    "    \n",
    "    #Get rating\n",
    "    rating = get_movie_value(soup,'MPAA')\n",
    "    \n",
    "    #Get release date\n",
    "    raw_release_date = get_movie_value(soup,'Release Date').split('\\n')[0]\n",
    "    release_date = to_date(raw_release_date)\n",
    "\n",
    "    #Get Genre\n",
    "    raw_genres = get_movie_value(soup, 'Genres')                \n",
    "    genres = raw_genres.split()[0]\n",
    "    \n",
    "    #Create movie dictionary and return\n",
    "    movie_dict = dict(zip(headers, [link_stub,\n",
    "                                    dd,\n",
    "                                    budget_value,\n",
    "                                domestic_total_gross,\n",
    "                                runtime,\n",
    "                                rating, \n",
    "                                release_date,\n",
    "                                    genres])) #removed title,\n",
    "\n",
    "    return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    \n",
    "    '''Grab a value from Box Office Mojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and returns the string in\n",
    "    the next sibling object (the value for that attribute) or None if nothing is found.\n",
    "    '''\n",
    "    \n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    \n",
    "    if not obj: \n",
    "        return None\n",
    "    \n",
    "    # this works for most of the values\n",
    "    next_element = obj.findNext()\n",
    "    \n",
    "    if next_element:\n",
    "        return next_element.text \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_page_info_list = []\n",
    "\n",
    "\n",
    "for link in g_movies_df.link_stub :\n",
    "    g_movies_page_info_list.append(get_movie_dict(link))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_page_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_page_info = pd.DataFrame(g_movies_page_info_list) #convert list of dict to df\n",
    "\n",
    "    \n",
    "g_movies_page_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_page_info.to_csv('g_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_df.set_index('link_stub', inplace=True)\n",
    "g_movies_page_info.set_index('link_stub', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g_movies_list = g_movies_df.merge(g_movies_page_info, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_list= g_movies_list.drop('lifetime_gross', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_list =  g_movies_list.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_list= g_movies_list.drop('link_stub', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g_movies_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g_movies_list.to_csv('main_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_movies_df.to_csv('gmovieslist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
